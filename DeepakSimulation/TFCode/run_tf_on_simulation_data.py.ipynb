{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import Data from Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "mat = spio.loadmat('../ReflectionModel/dataset_angle_simple.mat')\n",
    "features = mat['features']\n",
    "labels = mat['labels']\n",
    "print(len(features))\n",
    "print(len(features[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data to make it 0-mean, 1 variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186,)\n",
      "(100000, 186)\n",
      "(100000, 186)\n",
      "(100000, 1)\n",
      "[ 0.76299285]\n",
      "[ 2.13885275  2.12586838  2.11913876  2.112037    2.10288093  2.09555447\n",
      "  2.08996094  2.08706944  2.08379891  2.07853738  2.07279584  2.06910597\n",
      "  2.06775207  2.06388206  2.05790614  2.05680917  2.05478722  2.05082704\n",
      "  2.04846414  2.04444328  2.0396728   2.03278749  2.02767514  2.02123701\n",
      "  2.01924829  2.01533707  2.01171056  2.00839438  2.00073642  1.99245511\n",
      "  1.98750522  2.19434153  2.18236285  2.16909533  2.15698701  2.14764895\n",
      "  2.13388117  2.12405426  2.11431177  2.10784453  2.10130708  2.09162945\n",
      "  2.0795149   2.06860628  2.05490504  2.03912722  2.02548957  2.01226039\n",
      "  1.99936585  1.98677003  1.97416822  1.96021765  1.94736174  1.93514418\n",
      "  1.92510929  1.91220902  1.90244702  1.89393122  1.88494358  1.87339149\n",
      "  1.86132989  1.85025253  2.5108094   2.49401267  2.47814498  2.46367394\n",
      "  2.4494279   2.43750271  2.42160343  2.40791853  2.39654557  2.38574892\n",
      "  2.37260238  2.36128323  2.34734086  2.33553807  2.32488468  2.31512536\n",
      "  2.30405553  2.29004343  2.2742425   2.25697726  2.23741112  2.22053117\n",
      "  2.20586911  2.1966682   2.18644746  2.17740318  2.16489015  2.15728075\n",
      "  2.14677496  2.13606424  2.12668917  2.0989642   2.09442673  2.08356628\n",
      "  2.07368117  2.06555614  2.05566522  2.04441751  2.03052329  2.01689945\n",
      "  2.00577857  1.99489621  1.98243891  1.96729698  1.95508322  1.94494375\n",
      "  1.92986044  1.91599869  1.90429236  1.89071378  1.87930501  1.86870927\n",
      "  1.86053995  1.85047298  1.84215276  1.82879822  1.81789483  1.80669299\n",
      "  1.79533476  1.78869377  1.78298815  1.77346447  2.03130004  2.02585499\n",
      "  2.02224287  2.0172531   2.00938832  2.00672048  1.99996631  1.99292833\n",
      "  1.98283066  1.9728317   1.96613421  1.96229052  1.95734097  1.95537716\n",
      "  1.95599916  1.95396412  1.95190799  1.94934451  1.94690669  1.94442391\n",
      "  1.94345829  1.94113135  1.93878547  1.93410086  1.93207965  1.9272272\n",
      "  1.92158626  1.91641177  1.91351353  1.91140103  1.90839221  2.81045805\n",
      "  2.80442184  2.79765908  2.78994145  2.78230455  2.77282988  2.76664909\n",
      "  2.75867408  2.74903565  2.73910383  2.73131376  2.7219859   2.71523271\n",
      "  2.70661936  2.69731275  2.68729528  2.67867095  2.67242586  2.66800156\n",
      "  2.66489132  2.66375577  2.66029996  2.65555386  2.64611473  2.63779613\n",
      "  2.62858959  2.62197635  2.61192967  2.60412546  2.59660428  2.58844373]\n"
     ]
    }
   ],
   "source": [
    "feature_mean = np.mean(features,axis=0)\n",
    "label_mean = np.mean(labels,axis=0)\n",
    "label_std = np.std(labels,axis=0)\n",
    "feature_std = np.std(features,axis=0)\n",
    "print(feature_std.shape)\n",
    "feature_mean_m = np.tile(feature_mean, [len(features),1])\n",
    "feature_std_m = np.tile(feature_std, [len(features),1])\n",
    "label_mean_m = np.tile(label_mean,[len(labels),1])\n",
    "label_std_m = np.tile(label_std,[len(labels),1])\n",
    "print(feature_std_m.shape)\n",
    "features_normal = np.divide(features - feature_mean_m, feature_std_m)\n",
    "labels_normal = np.divide(labels- label_mean_m, label_std_m)\n",
    "print(features_normal.shape)\n",
    "print(labels_normal.shape)\n",
    "print(label_std)\n",
    "print(feature_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float64'>\n",
      "<type 'numpy.float32'>\n",
      "(60000, 186)\n",
      "[[ 0.41808215 -0.47943574  0.38616794 -0.21805754 -0.01301382  0.23585451\n",
      "  -0.40407693  0.47804517 -0.4022705   0.22515273]\n",
      " [ 0.42665854 -0.30114302  0.04161127  0.21832512 -0.39560214  0.47276425\n",
      "  -0.40188807  0.22286989  0.02494384 -0.2869508 ]\n",
      " [ 0.11848643 -0.4462274   0.50638551 -0.2792367  -0.13937524  0.45667034\n",
      "  -0.47120163  0.21638024  0.17445189 -0.49192542]\n",
      " [ 0.30815765 -0.52816898  0.41036683 -0.05713986 -0.35573241  0.5247069\n",
      "  -0.36773649 -0.01014095  0.36529934 -0.49651036]\n",
      " [ 0.55479205 -0.33839005 -0.21932279  0.56438237 -0.3991901  -0.14007214\n",
      "   0.52588093 -0.44491288 -0.0550025   0.49516603]\n",
      " [ 0.38972387 -0.39739358  0.3883346  -0.34669426  0.38122916 -0.37023512\n",
      "   0.37308007 -0.34772313  0.34754252 -0.34497473]\n",
      " [ 0.06836407 -0.06474066  0.07587463 -0.09786237  0.08641557 -0.10447545\n",
      "   0.12427203 -0.13410933  0.12846819 -0.13325036]\n",
      " [ 0.19032146 -0.35056889  0.41219044 -0.45743868  0.39379415 -0.25734654\n",
      "   0.07397553  0.0971316  -0.269308    0.37959602]\n",
      " [ 0.23074372 -0.68792903  0.06381661  0.66611606 -0.34574333 -0.50861454\n",
      "   0.56630188  0.28006119 -0.68258619  0.00387482]\n",
      " [-0.21333882  0.63718075 -0.21335393 -0.46311715  0.56252009  0.08605871\n",
      "  -0.61432475  0.35431665  0.37359038 -0.59275824]]\n"
     ]
    }
   ],
   "source": [
    "train_pts = 60000\n",
    "valid_pts = 20000\n",
    "test_pts = 20000\n",
    "print(type(features_normal[0][0]))\n",
    "features_normal = features_normal.astype('float32')\n",
    "print(type(features_normal[0][0]))\n",
    "labels_normal = labels_normal.astype('float32')\n",
    "train_dataset = (features_normal[0:train_pts ,:])\n",
    "train_labels = labels_normal[0:train_pts,:]\n",
    "valid_dataset = features_normal[train_pts:valid_pts+train_pts,:]\n",
    "valid_labels = labels_normal[train_pts:valid_pts+train_pts,:]\n",
    "test_dataset = features_normal[train_pts+valid_pts:train_pts+valid_pts+test_pts,:]\n",
    "test_labels = labels_normal[train_pts+valid_pts:train_pts+valid_pts+test_pts,:]\n",
    "print(train_dataset.shape)\n",
    "print(train_dataset[0:10,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup TensorFlow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2048\n",
    "num_hidden = [1024,512,256]\n",
    "depth = 4\n",
    "graph = tf.Graph()\n",
    "keep_prob = 0.9\n",
    "decay_rate = 0.5\n",
    "decay_steps = 1000\n",
    "num_features =features.shape[1]\n",
    "num_labels = labels.shape[1]\n",
    "print(num_features)\n",
    "def get_logits_for_training(dataset,w,b):\n",
    "    cur_mat = dataset\n",
    "    for i in range(0,depth-1):\n",
    "        cur_mat = tf.matmul(cur_mat,w[i])+b[i]\n",
    "        cur_mat = tf.nn.dropout(tf.nn.relu(cur_mat),keep_prob)\n",
    "    logits = tf.matmul(cur_mat,w[depth-1])+b[depth-1]\n",
    "    return logits\n",
    "\n",
    "def get_logits_for_prediction(dataset,w,b):\n",
    "    cur_mat = dataset\n",
    "    for i in range(0,depth-1):\n",
    "        cur_mat = tf.matmul(cur_mat,w[i])+b[i]\n",
    "        cur_mat = tf.nn.relu(cur_mat)\n",
    "    logits = tf.matmul(cur_mat,w[depth-1])+b[depth-1]\n",
    "    return logits\n",
    "    \n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, num_features))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  w = []\n",
    "  b = []\n",
    "  w.append(tf.Variable(tf.truncated_normal([num_features, num_hidden[0]],stddev=0.01)))\n",
    "  b.append(tf.zeros([num_hidden[0]]))\n",
    "  for i in range(1,depth-1):\n",
    "    w.append(tf.Variable(tf.truncated_normal([num_hidden[i-1],num_hidden[i]], stddev=0.01)))\n",
    "    b.append(tf.zeros([num_hidden[i]]))\n",
    "  w.append(tf.Variable(tf.truncated_normal([num_hidden[depth-2], num_labels],stddev=0.01)))\n",
    "  b.append(tf.Variable(tf.zeros([num_labels])))\n",
    "  \n",
    "  # Training computation.  \n",
    "  logits = get_logits_for_training(tf_train_dataset,w,b)\n",
    "  #loss = tf.reduce_mean(\n",
    "  #  tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits))\n",
    "  loss = tf.sqrt(tf.reduce_mean(tf.squared_difference(tf_train_labels, logits)))\n",
    "  #Optimizer\n",
    "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  learning_rate = tf.train.exponential_decay(0.5, global_step, decay_steps, decay_rate)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  # Optimizer.\n",
    "  #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  logits_predict = get_logits_for_prediction(tf_train_dataset,w,b)\n",
    "  train_prediction = (logits_predict)\n",
    "  valid_prediction = (get_logits_for_prediction(tf_valid_dataset,w,b))\n",
    "  test_prediction = (get_logits_for_prediction(tf_test_dataset,w,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 1: 0.998284\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.998\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994797707\n",
      "Minibatch loss at step 101: 0.996916\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.997\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993438721\n",
      "Minibatch loss at step 201: 0.997190\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.997\n",
      "Validation accuracy: 0.995\n",
      "Test accuracy: 0.9985618591\n",
      "Minibatch loss at step 301: 0.923328\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.924\n",
      "Validation accuracy: 0.891\n",
      "Test accuracy: 0.9057578444\n",
      "Minibatch loss at step 401: 0.471262\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.459\n",
      "Validation accuracy: 0.558\n",
      "Test accuracy: 0.5536177754\n",
      "Minibatch loss at step 501: 1.003580\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994711280\n",
      "Minibatch loss at step 601: 1.016550\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.017\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994658828\n",
      "Minibatch loss at step 701: 1.004637\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994684458\n",
      "Minibatch loss at step 801: 1.007579\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.008\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9995557666\n",
      "Minibatch loss at step 901: 0.988150\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.988\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994700551\n",
      "Minibatch loss at step 1001: 1.029141\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.029\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9995639920\n",
      "Minibatch loss at step 1101: 0.989472\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.989\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994654655\n",
      "Minibatch loss at step 1201: 1.001190\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.001\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9995042682\n",
      "Minibatch loss at step 1301: 1.002960\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.003\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994609356\n",
      "Minibatch loss at step 1401: 0.994981\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.995\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994635582\n",
      "Minibatch loss at step 1501: 0.992523\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994629622\n",
      "Minibatch loss at step 1601: 1.005198\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.005\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994652271\n",
      "Minibatch loss at step 1701: 0.994450\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.994\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993786216\n",
      "Minibatch loss at step 1801: 0.984398\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.984\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9992745519\n",
      "Minibatch loss at step 1901: 1.012279\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.012\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994602799\n",
      "Minibatch loss at step 2001: 0.995590\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.996\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994347095\n",
      "Minibatch loss at step 2101: 1.014425\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.014\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9990520477\n",
      "Minibatch loss at step 2201: 0.996876\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.997\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993966222\n",
      "Minibatch loss at step 2301: 1.020884\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.021\n",
      "Validation accuracy: 0.995\n",
      "Test accuracy: 0.9980402589\n",
      "Minibatch loss at step 2401: 0.993465\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994645119\n",
      "Minibatch loss at step 2501: 1.031068\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.031\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9992564321\n",
      "Minibatch loss at step 2601: 0.999373\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.999\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993693829\n",
      "Minibatch loss at step 2701: 1.002342\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.002\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994652271\n",
      "Minibatch loss at step 2801: 1.005565\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.006\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994609952\n",
      "Minibatch loss at step 2901: 0.991801\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.992\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994662404\n",
      "Minibatch loss at step 3001: 0.991246\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.991\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994619489\n",
      "Minibatch loss at step 3101: 1.010677\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.011\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994664192\n",
      "Minibatch loss at step 3201: 1.007141\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.007\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994619489\n",
      "Minibatch loss at step 3301: 0.994932\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.995\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994658828\n",
      "Minibatch loss at step 3401: 1.003004\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.003\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994609356\n",
      "Minibatch loss at step 3501: 0.993470\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994618893\n",
      "Minibatch loss at step 3601: 1.017033\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.017\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994610548\n",
      "Minibatch loss at step 3701: 0.982857\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.983\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994620681\n",
      "Minibatch loss at step 3801: 1.004526\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.005\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994623661\n",
      "Minibatch loss at step 3901: 0.986296\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.986\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994622469\n",
      "Minibatch loss at step 4001: 1.017142\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.017\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994636178\n",
      "Minibatch loss at step 4101: 0.999618\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.000\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994611740\n",
      "Minibatch loss at step 4201: 1.002099\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.002\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994624853\n",
      "Minibatch loss at step 4301: 0.997095\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.997\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994493127\n",
      "Minibatch loss at step 4401: 0.989272\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.989\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993534088\n",
      "Minibatch loss at step 4501: 0.992904\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993361235\n",
      "Minibatch loss at step 4601: 1.003675\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993028045\n",
      "Minibatch loss at step 4701: 0.994029\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.994\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9992595911\n",
      "Minibatch loss at step 4801: 1.003550\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.003\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9992271066\n",
      "Minibatch loss at step 4901: 1.000189\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.000\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9991207123\n",
      "Minibatch loss at step 5001: 1.003644\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9990562797\n",
      "Minibatch loss at step 5101: 1.003702\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9989970922\n",
      "Minibatch loss at step 5201: 0.982567\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.983\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9988040328\n",
      "Minibatch loss at step 5301: 0.998285\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.998\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9988253713\n",
      "Minibatch loss at step 5401: 0.999364\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.999\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9989461303\n",
      "Minibatch loss at step 5501: 1.005622\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.006\n",
      "Validation accuracy: 0.995\n",
      "Test accuracy: 0.9980213642\n",
      "Minibatch loss at step 5601: 0.994900\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.995\n",
      "Validation accuracy: 0.994\n",
      "Test accuracy: 0.9975852966\n",
      "Minibatch loss at step 5701: 1.004477\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.003\n",
      "Validation accuracy: 0.994\n",
      "Test accuracy: 0.9974892139\n",
      "Minibatch loss at step 5801: 0.992039\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.994\n",
      "Validation accuracy: 0.994\n",
      "Test accuracy: 0.9967331290\n",
      "Minibatch loss at step 5901: 0.984864\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.985\n",
      "Validation accuracy: 0.993\n",
      "Test accuracy: 0.9963192940\n",
      "Minibatch loss at step 6001: 1.001862\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.001\n",
      "Validation accuracy: 0.992\n",
      "Test accuracy: 0.9953783154\n",
      "Minibatch loss at step 6101: 1.010953\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.011\n",
      "Validation accuracy: 0.992\n",
      "Test accuracy: 0.9945317507\n",
      "Minibatch loss at step 6201: 0.999756\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9992073178\n",
      "Minibatch loss at step 6301: 1.012051\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.012\n",
      "Validation accuracy: 0.992\n",
      "Test accuracy: 0.9945356846\n",
      "Minibatch loss at step 6401: 0.983258\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.984\n",
      "Validation accuracy: 0.989\n",
      "Test accuracy: 0.9919553399\n",
      "Minibatch loss at step 6501: 0.994064\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.994\n",
      "Validation accuracy: 0.988\n",
      "Test accuracy: 0.9904864430\n",
      "Minibatch loss at step 6601: 1.001025\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.001\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9991341829\n",
      "Minibatch loss at step 6701: 0.968625\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.969\n",
      "Validation accuracy: 0.986\n",
      "Test accuracy: 0.9882664084\n",
      "Minibatch loss at step 6801: 0.992789\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.984\n",
      "Test accuracy: 0.9863349795\n",
      "Minibatch loss at step 6901: 1.008674\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.009\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9995317459\n",
      "Minibatch loss at step 7001: 1.012533\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.013\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994851351\n",
      "Minibatch loss at step 7101: 0.984410\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.985\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994618297\n",
      "Minibatch loss at step 7201: 1.002932\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994531274\n",
      "Minibatch loss at step 7301: 0.992598\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.994\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994369149\n",
      "Minibatch loss at step 7401: 0.991771\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9994248152\n",
      "Minibatch loss at step 7501: 0.992653\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.994\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993720055\n",
      "Minibatch loss at step 7601: 1.011558\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.013\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9993455410\n",
      "Minibatch loss at step 7701: 1.010310\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.012\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9992603064\n",
      "Minibatch loss at step 7801: 1.017156\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.019\n",
      "Validation accuracy: 0.996\n",
      "Test accuracy: 0.9991290569\n",
      "Minibatch loss at step 7901: 1.003296\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.004\n",
      "Validation accuracy: 0.995\n",
      "Test accuracy: 0.9983890057\n",
      "Minibatch loss at step 8001: 1.010728\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 1.011\n",
      "Validation accuracy: 0.991\n",
      "Test accuracy: 0.9941674471\n",
      "Minibatch loss at step 8101: 0.988967\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.989\n",
      "Validation accuracy: 0.979\n",
      "Test accuracy: 0.9814813137\n",
      "Minibatch loss at step 8201: 0.965613\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.966\n",
      "Validation accuracy: 0.978\n",
      "Test accuracy: 0.9802183509\n",
      "Minibatch loss at step 8301: 0.978889\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.979\n",
      "Validation accuracy: 0.977\n",
      "Test accuracy: 0.9788261056\n",
      "Minibatch loss at step 8401: 0.980240\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.980\n",
      "Validation accuracy: 0.976\n",
      "Test accuracy: 0.9776548743\n",
      "Minibatch loss at step 8501: 0.993700\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.993\n",
      "Validation accuracy: 0.975\n",
      "Test accuracy: 0.9767685533\n",
      "Minibatch loss at step 8601: 0.947982\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.949\n",
      "Validation accuracy: 0.973\n",
      "Test accuracy: 0.9753470421\n",
      "Minibatch loss at step 8701: 0.993349\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.985\n",
      "Validation accuracy: 0.973\n",
      "Test accuracy: 0.9759396315\n",
      "Minibatch loss at step 8801: 0.969127\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.969\n",
      "Validation accuracy: 0.971\n",
      "Test accuracy: 0.9738152623\n",
      "Minibatch loss at step 8901: 0.970911\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.972\n",
      "Validation accuracy: 0.970\n",
      "Test accuracy: 0.9719282389\n",
      "Minibatch loss at step 9001: 0.969475\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.970\n",
      "Validation accuracy: 0.969\n",
      "Test accuracy: 0.9720674157\n",
      "Minibatch loss at step 9101: 0.985992\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.985\n",
      "Validation accuracy: 0.971\n",
      "Test accuracy: 0.9737898111\n",
      "Minibatch loss at step 9201: 0.985813\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.985\n",
      "Validation accuracy: 0.967\n",
      "Test accuracy: 0.9690470099\n",
      "Minibatch loss at step 9301: 0.997943\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.991\n",
      "Validation accuracy: 0.966\n",
      "Test accuracy: 0.9687592387\n",
      "Minibatch loss at step 9401: 0.972451\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.973\n",
      "Validation accuracy: 0.964\n",
      "Test accuracy: 0.9658215642\n",
      "Minibatch loss at step 9501: 0.984843\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.984\n",
      "Validation accuracy: 0.964\n",
      "Test accuracy: 0.9662415981\n",
      "Minibatch loss at step 9601: 0.968754\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.968\n",
      "Validation accuracy: 0.962\n",
      "Test accuracy: 0.9646998644\n",
      "Minibatch loss at step 9701: 0.959790\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.959\n",
      "Validation accuracy: 0.965\n",
      "Test accuracy: 0.9672574401\n",
      "Minibatch loss at step 9801: 0.973501\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.972\n",
      "Validation accuracy: 0.960\n",
      "Test accuracy: 0.9614281654\n",
      "Minibatch loss at step 9901: 0.957731\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.957\n",
      "Validation accuracy: 0.959\n",
      "Test accuracy: 0.9607266188\n",
      "Minibatch loss at step 10001: 0.977635\n",
      "(1024, 512)\n",
      "Minibatch accuracy: 0.976\n",
      "Validation accuracy: 0.959\n",
      "Test accuracy: 0.9608567953\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return np.sqrt(((predictions - labels) ** 2).mean())\n",
    "\n",
    "def accuracy_xy(predictions,labels):\n",
    "    return (np.sqrt(((predictions[:,0] - labels[:,0]) ** 2).mean()),np.sqrt(((predictions[:,1] - labels[:,1]) ** 2).mean()))\n",
    "    \n",
    "num_steps = 10002\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions,l1 = session.run(\n",
    "      [optimizer, loss, train_prediction,w], feed_dict=feed_dict)\n",
    "    if (step % 100 == 1):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(l1[1].shape)\n",
    "        \n",
    "      print(\"Minibatch accuracy: %.3f\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.3f\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.10f\" % accuracy(test_prediction.eval(), test_labels))\n",
    "     # print(accuracy_xy(test_prediction.eval(),test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
